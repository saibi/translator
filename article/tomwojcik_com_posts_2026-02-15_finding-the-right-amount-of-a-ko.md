> 원문 출처: https://tomwojcik.com/posts/2026-02-15/finding-the-right-amount-of-ai/

# AI 코딩이 당신에게 치르게 하는 대가

**작성: Tom Wojcik**
**게시일: 2026년 2월 15일**

태그: ai | claude | essay

---

내가 아는 개발자는 이제 모두 AI를 사용해서 코딩한다. 생산성 향상은 실재하지만, 어떤 대시보드에도 나타나지 않는 비용이 존재한다.

스펙트럼을 하나 상상해보자. 맨 왼쪽 끝에는 IDE에서 코드를 직접 보며 키보드를 두드리는 인간이 있다. 맨 오른쪽 끝에는 AGI가 있다. AGI는 모든 것을 스스로 구현한다. 저렴하게, 완벽하게, 어떤 인간보다 뛰어나게, 그리고 인간 감독자 없이도. 그 두 극단 사이 어딘가에 AI를 사용하고 있는 지금의 당신이 있다. 그 임계점은 모델이 개선되고, 도구가 성숙하고, 워크플로우가 정제될수록 매주 오른쪽으로 이동하고 있다.

최근 나는 HN의 daxfohl 댓글을 우연히 발견했다:

> "AI를 너무 많이 쓰는 것과 너무 적게 쓰는 것 중 어느 쪽이 더 위험한가?"

이 댓글은 특히 다양한 직장에서의 AI 도입에 관해 다른 개발자들이 공유하는 내용을 읽고 난 후, LLM의 코딩 활용에 대해 다르게 생각하게 만들었다. 양방향 모두 틀릴 수 있지만, 모델이 발전함에 따라 직장에서의 적정 AI 사용량은 변하고 있을까?

## 우리가 여기까지 온 과정

얼마 전, Cursor(2023년)나 Copilot(2022년) 같은 최초의 AI 코딩 도구가 등장했다. 이 도구들은 RAG(검색 증강 생성)를 사용해 코드베이스를 빠르게 색인화할 수 있었으므로 로컬 컨텍스트를 확보했다. 모델에 내장된 모든 지식 덕분에 인터넷이라는 외부 지식도 활용할 수 있었다. Google 검색이나 StackOverflow를 뒤지는 일은 더 이상 필요하지 않았다. Cursor는 사용자에게 AI 기반 자동완성과 채팅 같은 AI 도구가 내장된 맞춤형 IDE를 제공하여 경험을 일관되게 만들었다.

그리고 에이전트의 약속이 찾아왔다. MCP(Model Context Protocol), 자율 워크플로우, 에이전트가 밤새 돌아간다는 기사들이 사방에서 쏟아졌다. 이것은 Cursor와는 다른 AI 활용이었다. **더 이상 AI가 보조하는 인간의 코딩이 아니라, 인간이 보조하는 AI의 코딩이었다.**

많은 개발자들이 시도해보고 화상을 입었다. 에이전트는 수많은 작은 실수를 저질렀다. AI 우선(AI-first) 프로세스는 훌륭한 결과를 내기 위해 개발자들이 코딩에 대해 생각하는 방식 자체의 완전한 패러다임 전환을 요구했다. 또한 에이전트는 종종 루프에 빠지거나, 의존성을 환각(hallucinate)하거나, 거의 맞는 것 같지만 실제로는 틀린 코드를 생산했다. FOMO(놓치는 것에 대한 두려움)에 휩쓸려 완전히 새로운 기술을 익혀야 했지만, 이 반짝이는 새 도구는 첫 번째 시도에서 100%를 달성하지 못했다.

소프트웨어는 원래 결정론적이었다. if/else 분기, 명시적인 상태 머신(state machine), 명확한 로직으로 제어했다. 새로운 현실은 프롬프트, 시스템 지침(system instruction), `CLAUDE.md` 파일로 개발 프로세스를 제어하며 모델이 예상한 출력을 내놓기를 바라는 것이다.

그리고 Opus 4.5가 출시됐다.

모두가 이야기하던 워크플로우가 (항상 그런 건 아니지만, 더 자주) 처음부터 작동했다. 엔지니어들은 Forward Deployed Engineer(현장 배포 엔지니어)로 전환되어, 코딩 외에도 많은 것을 책임지게 됐다. 때로는 직접 코딩조차 하지 않기도 한다. 최근 Spotify의 공동 CEO 구스타프 쇠데르스트룀(Gustav Söderström)은 이렇게 말했다:

> "Spotify 엔지니어가 출근길 지하철에서 휴대폰의 Slack으로 Claude에게 버그를 고치거나 iOS 앱에 새 기능을 추가하라고 말할 수 있습니다. Claude가 작업을 마치면 엔지니어는 Slack으로 새 버전의 앱을 받아 사무실에 도착하기도 전에 프로덕션에 머지할 수 있습니다."

그들이 적어도 머지 전에 코드를 검토하기를 바란다.

다음 단계는 (거의) 완전한 자동화다. 그것이 많은 임원들이 원하고 달성하려는 것이다. 절대 잠들지 않고, 절대 지치지 않고, 항상 일하고 싶어 하며, 무한히 생산적인 노동자라는 자본주의적 꿈이다. 하지만 제프리 힌튼(Geoffrey Hinton)은 2016년에 딥러닝이 5년 안에 방사선과 전문의를 이미지 분석에서 능가할 것이라고 예측했다. Anthropic의 CEO는 2025년 3월로부터 3~6개월 안에 AI가 코드의 90%를 작성할 것이라고 예측했다. 이 중 어느 것도 예측대로 이루어지지 않았다. 방향은 맞지만, 타임라인은 계속 미끄러진다.

## AI를 쓰면 뇌에 무슨 일이 생기나

2012년 신경과학자 만프레드 스피처(Manfred Spitzer)는 『디지털 치매(Digital Dementia)』를 출판했다. 그는 정신적 작업을 디지털 기기에 아웃소싱할 때 그 작업을 담당하는 뇌의 신경 경로가 위축된다고 주장했다. 쓰지 않으면 잃는다. 이것이 과학적으로 모두 입증된 건 아니지만, 신경가소성(neuroplasticity) 연구는 뇌가 사용되는 경로를 강화하고 사용되지 않는 경로를 약화시킨다는 것을 보여준다. 이 책의 핵심 원칙은 연습을 멈춘 인지 능력은 쇠퇴한다는 것이다.

소프트웨어 공학 연구자 마거릿-앤 스토리(Margaret-Anne Storey)는 최근 이것에 더 정확한 이름을 붙였다: **인지적 부채(cognitive debt)**. 기술적 부채(technical debt)는 코드 안에 존재한다. 인지적 부채는 개발자의 머릿속에 존재한다. 이해 없이 빠르게 구축할 때 축적되는 이해의 누적 손실이다. 그녀는 이것을 피터 나우르(Peter Naur)의 1985년 이론에 근거한다. 이 이론에 따르면 프로그램은 개발자의 마음속에 존재하는 이론으로서, 프로그램이 무엇을 하는지, 의도가 어떻게 구현에 매핑되는지, 어떻게 진화할 수 있는지를 포착한다. 그 이론이 파편화되면 시스템은 블랙박스가 된다.

이것을 완전 에이전트(fully agentic) 코딩에 직접 적용해보자. 코드 작성을 멈추고 AI 출력만 검토한다면, 코드에 대한 추론 능력이 위축된다. 천천히, 눈에 보이지 않게, 하지만 불가피하게. 더 이상 깊이 이해할 수 없는 것을 깊이 검토할 수 없다.

이것은 단순한 이론이 아니다. 2026년 Shen과 Tamkin의 무작위 대조 연구는 이것을 직접 검증했다. 새로운 비동기 라이브러리를 학습하는 52명의 전문 개발자를 AI 보조 그룹과 비보조 그룹으로 나누었다. AI 그룹은 개념 이해, 디버깅, 코드 읽기에서 **17% 낮은 점수**를 받았다. 가장 큰 격차는 디버깅에서 나타났다. 그것은 바로 AI가 틀리는 부분을 잡아내기 위해 필요한 능력이다. 단 한 시간의 수동적인 AI 보조 작업만으로도 측정 가능한 기술 저하가 발생했다.

교활한 점은 도구가 그 저하를 보상해주기 때문에 자신의 쇠퇴를 알아채지 못한다는 것이다. 생산적이라고 느낀다. PR은 계속 머지된다. 미하이 칙센트미하이(Mihaly Csikszentmihalyi)의 플로우(flow) 연구는 플로우 상태가 도전과 기술 사이의 균형에 달려 있다고 했다. 마음이 딱 충분히 확장되어야 한다. 진정한 플로우는 성장을 만들어낸다. 레이첼 토머스(Rachel Thomas)는 AI 보조 작업이 만들어내는 것을 "어두운 플로우(dark flow)"라고 불렀다. 슬롯머신이 유도하도록 설계된 황홀경 같은 상태를 묘사하는 도박 연구에서 빌린 용어다. 몰입한 것처럼 느껴지지만 AI가 도전을 처리하기 때문에 도전-기술 균형이 무너진다. 깊은 작업의 플로우 상태처럼 느껴지지만, 피드백 루프가 끊어져 있다. 더 나아지는 게 아니라 의존하게 되는 것이다.

### 코드 작성 없이 검토만 하기

HN 댓글에서 계속 나오는 관찰이 있다: AI가 모든 코드를 작성하고 당신이 그것만 검토한다면, 검토하는 기술은 어디서 오는가? 둘 중 하나 없이는 다른 하나를 가질 수 없다. 교과서나 PR을 읽어서 좋은 코드를 알아보는 법을 배우는 게 아니다. 나쁜 코드를 작성하고, 그것이 완전히 분해되고, 수년간의 실전을 통해 직관을 쌓으면서 배우는 것이다.

이것이 내가 "검토의 역설(review paradox)"이라고 부르는 것을 만든다. AI가 더 많이 쓸수록, 인간은 AI가 작성한 것을 검토할 자격을 잃어간다. Shen-Tamkin 연구는 이것을 수치로 보여준다. AI에게 완전히 위임한 개발자들은 작업을 가장 빨리 끝냈지만 평가에서 가장 낮은 점수를 받았다. AI 생산성으로 가장 많은 혜택을 받는 초보자들이 바로 AI를 감독하기 위한 디버깅 기술이 가장 필요한 사람들이고, AI는 그런 기술을 가장 먼저 깎아먹는다.

스토리가 제안한 해결책은 간단하다: "인간이 배포 전에 AI가 생성한 각 변경 사항을 이해하도록 요구하라." 그게 맞는 답이다. 그리고 속도(velocity)가 지표일 때 가장 먼저 건너뛰게 되는 것이기도 하다.

### 시니어리티(Seniority)의 붕괴

이것은 개인의 기술 저하보다 더 깊은 문제다. 우리는 과거에 주니어, 미드레벨, 시니어, 스태프 엔지니어, 아키텍트 같은 직급 체계를 가지고 있었다. 각 레벨이 수년간의 실전 경험을 통한 고생 위에 쌓이는 파이프라인이었다. 주니어는 조심하지 않아서가 아니라 몰랐기 때문에 코드 리뷰에서 거절당하는 코드를 수년간 작성한다. 그것이 단순히 함수를 작성할 줄 아는 사람과 시스템을 설계할 줄 아는 사람을 구분하는 판단력을 쌓는 방법이다. 하룻밤 사이에 시니어가 될 수는 없다.

물론, AI를 사용하지 않는다면 말이다. 이제 Claude Code(Opus 4.5+)를 사용하는 주니어는 시니어 엔지니어 수준의 PR을 제출한다. 전반적으로 이것은 좋은 일이라고 생각한다. 하지만 이제 모두가 첫날부터 시니어 모자를 쓸 수 있다는 뜻인가? 하지만 그 모자 안의 머리는 변하지 않았다. 그 주니어는 왜 그 아키텍처가 선택됐는지 모른다. 내 경험상, Claude Code(CC)는 종종 DB 트랜잭션이 필요한 곳에서 놓치기도 한다. 때로는 여러 이유로 잠가서는 안 될 리소스에 락(lock)을 건다. 나는 내 결정을 방어할 수 있고, 코드에 도전받고 리뷰어가 동의하지 않아 토론하는 것을 즐긴다. 주니어는 어떻게 할까? Claude에게 물어볼 것이다.

이것은 양면적인 붕괴다. 코드 작성을 멈추고 AI 출력만 검토하는 시니어들은 자신의 깊이를 잃어간다. 고생을 건너뛰는 주니어들은 그것을 쌓지 못한다. 조직들은 매일 리뷰에 시니어 시간을 소모하면서 동시에 그것을 만들어내는 메커니즘을 망가뜨리고 있다. 나쁜 코드를 작성하고, 나쁜 코드가 리뷰되고, 실패를 통해 직관을 쌓던 시니어 엔지니어를 만들어내는 파이프라인이 완전히 우회되고 있다. 그 파이프라인이 고갈되면 어떻게 되는지에 대해서는 아무도 이야기하지 않는다.

## C레벨이 옳게 본 것과 틀리게 본 것

C레벨 임원들의 책상에 매주 어떤 것들이 올라오는지 보자. Microsoft의 AI 수장 무스타파 술레이만(Mustafa Suleyman)은 18개월 안에 모든 화이트칼라 업무가 자동화될 것이라고 말한다. Anthropic의 CEO 다리오 아모데이(Dario Amodei)는 AI가 6~12개월 안에 소프트웨어 엔지니어를 대체할 것이라고 예측하며, 자신의 엔지니어들이 더 이상 코드를 직접 작성하지 않고 모델이 작성하게 한 후 출력을 편집한다고 말했다. 순다르 피차이(Sundar Pichai, CEO, Google)는 2024년 말 Google 신규 코드의 25%가 AI로 생성됐다고 보고했다. 몇 달 후 Google Research는 그 수치가 코드 문자 기준 50%에 도달했다고 보고했다. 그 커브를 지켜보는 CTO라면 당연히 팀을 밀어붙일 것이다.

문제는 이런 예측들이 AI를 팔거나 주가를 AI 과대광고로 부양하려는 사람들에게서 나온다는 것이다. 그들은 채택을 가속화할 모든 인센티브가 있고 타임라인이 빗나갈 때의 책임은 전혀 없다. 그리고 역사적으로 타임라인은 항상 빗나갔다. 그리고 자체 모델, 도구, 인프라를 처음부터 구축해온 Google의 "코드 문자의 50%"가 당신의 팀이 다음 월요일에 기성품 에이전트로 무엇을 달성할 수 있는지에 대해 말해주는 것은 거의 없다.

AI 도입은 켜고 끌 수 있는 스위치가 아니라 조율해야 할 기술이다. 특정 도구를 의무화하거나, "AI 우선(AI-first)" 정책을 설정하거나, AI 사용량으로 개발자를 평가하는 것처럼 단순하지 않다. 디자인 패턴 활용, 적절한 테스트 커버리지, 머지 전 수동 테스트 같은 많은 좋은 관행들이 요즘 속도를 늦춘다는 이유로 종종 건너뛰어진다. AI가 망가뜨렸나? AI가 고칠 것이다. 리뷰가 필요한가? AI가 할 것이다. Greptile이나 CodeRabbit도 아니고, 그냥 PR을 Claude Code 리뷰어 에이전트에게 위임한다. 아니면 Gemini. 아니면 Codex. 마음에 드는 것으로 고르면 된다.

AI 사용을 강제하면 실제로 어떤 일이 일어나는지 보자. 한 개발자는 엔지니어별 AI 사용량을 추적하는 회사를 묘사했다: "저는 그냥 신경도 안 쓰는 무작위 작업을 봇에게 시키기 시작했어요. 얼마 전에는 Claude에게 '버그를 찾으라'거나 이미 답을 아는 질문을 하면서 임의의 디렉터리를 살펴보게 했어요." 다른 스레드는 "도구에서 손 뗀 지 오래되어 위험해진 테크 리드들이 만들어내는 AI 슬롭(slop) 때문에 코드 리뷰가 무한히 어려워졌다"고 보고하는 엔지니어들로 가득했다.

이것은 슬픈 일이다. AI 도구를 잘 쓰는 것은 개발자에게 혜택이고, 속도를 높이기 때문에 경영진도 원하는 것이다. 지표를 조작하는 사람들(AI를 제대로 사용하지 않는)은 경영진이 그들이 지표를 조작하는 방법을 알게 되면 즉시 해고될 것이 분명하지만(그리고 그것은 타당하지만), 그들이 지표를 조작하는 이유는 해고되기 싫어서다…

회사에서 AI 사용 임계값을 설정하는 책임은 누구에게 있어야 하는가? 최고 성과를 내는 엔지니어가 AI 사용을 거부한다면? 새로 채용된 주니어가 AI를 항상 쓴다면? 이것이 새로운 질문들이고, 경영진은 답을 찾으려 하지만 AI 사용량을 측정하는 것만큼 단순하지 않다.

이것은 굿하트의 법칙(Goodhart's Law)이 작동하는 것이다: "어떤 척도가 목표가 되면, 그것은 좋은 척도이기를 멈춘다." 엔지니어별 AI 사용량을 추적하면 더 나은 엔지니어링이 아니라 형식적인 순응(compliance theater)만 얻게 된다. 개발자들은 지표를 조작하고, 도구를 원망하고, AI가 실제로 제공할 수 있는 생산성 향상은 조직적 역기능 아래 파묻힌다.

## 아무도 이야기하지 않는 비용

재정적 비용은 명확하다. 비트리비얼(non-trivial)한 기능에 대한 에이전트 시간은 시간 단위로 측정되고, 그 시간은 공짜가 아니다. 하지만 인간적 비용은 잠재적으로 더 심각하고, 거의 논의되지 않는다.

앞서 언급했듯이 코드 작성은 플로우 상태에 들어가게 할 수 있다. 몇 시간이 사라지고, 직접 이해하며 만든 무언가와 함께 나오는 깊고 집중적이며 창의적인 문제 해결 상태. 그리고 그것이 자랑스럽다. 누군가가 당신의 PR 아래에 "잘했어요!"라고 쓰고 승인을 눌렀다. AI가 생성한 코드를 검토하는 것은 그렇지 않다. 정반대다. 정신적으로 소진된다.

개발자들은 창조의 도파민 자극이 필요하다. 그것은 부수적인 혜택이 아니라 뛰어난 엔지니어들을 참여하게 하고, 배우게 하고, 유지하게 하며, 번아웃을 막는 것이다. 코딩의 즐거움이 아마도 처음에 그들이 경험 있는 개발자가 될 수 있게 한 것이다. 창조를 감독으로 대체하면 더 빠른 배포가 아니라 더 빠른 번아웃을 얻는다. 당신은 엔지니어링, 즉 창의적인 작업을 최악의 형태의 QA로 바꿨다. AI가 모든 예술을 하고, 인간은 빨래를 개킨다.

## 당신의 임계값 찾기

나는 매일 AI를 사용한다. 직장에서도, 사이드 프로젝트에서도 AI를 많이 쓰고, 이전으로 돌아가고 싶지 않다. 정말 좋다! 그래서 걱정된다. 내가 중독되고 의존하게 됐다는 것이 두렵다. 나는 수많은 커스텀 명령, 스킬, 에이전트를 구현했다. Claude Code 릴리스 노트를 매일 확인한다. 지금 많은 사람들이 비슷한 상황에 있고, 우리 모두는 미래에 무엇이 올지 궁금해한다. 우리는 AI로 스스로를 대체하게 될까? 아니면 AI 슬롭을 청소하는 책임을 지게 될까? 나에게 적정한 AI 사용량은 얼마인가?

AI는 단지 도구다. 엄청나게 강력한 도구이지만, 도구일 뿐이다. 모든 엔지니어에게 특정 IDE를 사용하도록 의무화하거나, 하루에 몇 줄을 작성하는지로 사람을 평가하지 않을 것이다(…그렇지 않은가?). 각자 가장 효과적으로 만드는 도구를 선택하게 하고, 실제로 중요한 것, 즉 출시되는 작업을 측정할 것이다.

적정 AI 사용량은 0이 아니다. 그리고 최대도 아니다.

Shen-Tamkin 연구는 개발자들 사이에서 6가지 뚜렷한 AI 상호작용 패턴을 확인했다. 세 가지는 나쁜 학습으로 이어졌다: 완전한 위임(full delegation), 점진적 의존(progressive reliance), 그리고 디버깅을 AI에게 아웃소싱하기. 세 가지는 AI 완전 접근 권한이 있어도 학습을 보존했다: 설명 요청하기, 개념적 질문 제기하기, 그리고 명확화를 위해 AI를 사용하면서 독립적으로 코드 작성하기. 차이를 만드는 것은 개발자들이 AI를 사용했느냐가 아니라, 인지적으로 참여 상태를 유지했느냐였다.

소프트웨어 엔지니어링은 결코 단지 코드를 타이핑하는 것이 아니었다. 문제를 잘 정의하고, 문제를 이해하고, 비즈니스에서 제품으로, 코드로 언어를 번역하고, 모호함을 명확히 하고, 트레이드오프를 만들고, 무언가를 바꿀 때 무엇이 깨지는지 이해하는 것이다. AGI 이전에 누군가가 그것을 해야 하고, AGI는 아직 가깝지 않다(다행히도). 당신은 온콜 상태이고, 새벽 3시에 전화가 온다. 에이전트 없이 이슈를 분류(triage)할 수 있는가? 그렇지 못하다면, 아마도 AI 코딩을 너무 멀리 밀어붙인 것이다. AI 사용이 개발자의 새로운 성과 지표가 된다면, 너무 자주, 너무 많이 AI를 사용하는 것은 아마도 오히려 권장되지 않아야 할 것이다. 이 도구들이 나쁘기 때문이 아니라, 코딩 기술이 유지할 가치가 있기 때문에.

### 너무 적게 쓸 때의 위험 (일화적 데이터)

2026년에 AI를 전혀 사용하지 않는다면, 실제 이득을 놓치고 있는 것이다:

* **검색과 컨텍스트.** AI는 익숙하지 않은 코드베이스를 탐색하고, 레거시 코드를 이해하고, 관련 패턴을 찾는 데 Google보다 훨씬 뛰어나다. 이것만으로도 워크플로우에 도입할 이유가 된다 (2023년부터, Cursor 등)
* **보일러플레이트와 스캐폴딩.** 에이전트가 몇 초 안에 생성할 수 있을 때 백 번째 CRUD 엔드포인트, 설정 파일, 테스트 스캐폴드를 손으로 작성하는 것은 장인 정신이 아니라 고집이다. 그냥 AI를 써라. 어차피 요즘 우리 모두 여러 가지 역할을 맡기 때문에 더 이상 CRUD 개발자가 아니다 (2025년 이후 Sonnet)
* **워크플로우 자체.** 커스터마이즈된 에이전트와 함께 작동하는 조사-계획-구현-테스트-검증 사이클은 기능이 제공되는 방식의 실질적인 개선이다. 비트리비얼한 작업에 수일이 아닌 수시간이 걸린다. 약속됐던 10배는 아니지만, 기존 코드베이스에서 2배 또는 4배는 쉽게 얻을 수 있다. 하지만 출력과 AI가 내린 모든 결정을 반드시 이해해야 한다! (2025년 Opus 4.5 이후)
* **탐색.** "이 모듈은 무엇을 하는가? 이 API는 어떻게 작동하는가? 이것을 변경하면 무엇이 깨지는가?" AI는 이런 질문들에 탁월하다. 코드를 직접 읽는 것을 대체하지 않겠지만, 빠른 시간 안에 올바른 파일로 안내해준다. (2023년부터)

원칙상 AI 사용을 거부하는 것은 과대광고에 의해 채택하는 것만큼 비합리적이다.

### 너무 많이 쓸 때의 위험 (일화적 데이터 및 내 예측)

자율 AI 코딩에 완전히 올인한다면 (특히 실제로 어떻게 작동하는지 배우지 않고), 느린 속도보다 더 나쁜 것, 즉 **보이지 않는** 저하를 위험에 빠뜨린다:

* **기능처럼 보이는 버그.** AI가 생성한 코드가 CI를 통과한다. 타입 검사도 통과한다. 테스트도 녹색이다. 그리고 그 안 어딘가에 미묘한 논리 오류, 환각된 엣지 케이스, 부하 아래서 무너질 패턴이 있다. 금융이나 헬스케어 같은 도메인에서 오류를 발생시키지 않는 잘못된 숫자는 크래시보다 더 나쁘다. (점점 덜 관련적이지만, 여전히 관련 있음)
* **아무도 이해하지 못하는 코드베이스.** 에이전트가 모든 것을 작성하고 인간이 검토만 한다면, 6개월 후 팀의 누구도 시스템이 왜 그렇게 설계됐는지 설명할 수 없게 된다. AI가 결정을 내렸다. 테스트가 통과됐기 때문에 아무도 그것에 의문을 제기하지 않았다. 스토리는 정확히 이 벽에 부딪힌 학생 팀을 묘사한다. 그들은 무언가를 망가뜨리지 않고는 간단한 변경을 할 수 없었는데, 문제는 코드가 지저분한 것이 아니라 특정 설계 결정이 왜 이루어졌는지 아무도 설명할 수 없다는 것이었다. 그녀의 결론: "이해 없는 속도는 지속 가능하지 않다." (항상 문제가 될 것, 개인적으로)
* **인지 위축.** 디지털 치매 섹션의 모든 내용. 연습을 멈춘 기술은 쇠퇴한다. (항상 문제가 될 것, 개인적으로)
* **시니어리티 파이프라인 고갈.** 위에서도 다뤘다. 이것은 나타나는 데 수년이 걸리는데, 그것이 바로 아무도 대비하지 않는 이유다. (새로운 문제, 미래가 어떻게 될지 모름)
* **번아웃.** 창조의 도파민 없이 하루 종일 AI 출력을 검토하는 것은 지속 가능한 직무 설명이 아니다. (오래된 문제이지만 잠재적으로 더 빨리 닥침?)

## 조용한 쇠퇴

이것이 밤에 나를 깨어있게 하는 것이다. 모든 대시보드의 모든 지표로 볼 때, AI 보조 인간 개발과 인간 보조 AI 개발은 개선되고 있다. 더 많은 PR이 머지됐다. 더 많은 기능이 제공됐다. 더 빠른 사이클 타임. 차트는 위로, 오른쪽으로 올라간다.

하지만 지표들은 그 밑에서 무슨 일이 일어나는지를 포착하지 못한다. 당신이 쓰지 않은 코드를 하루 종일 검토하는 정신적 피로. 문제를 해결하는 대신 에이전트를 돌보는 지루함. 이 직업에서 당신을 능력 있게 만들었던 하드 스킬의 느리고 눈에 보이지 않는 침식. 에이전트가 처리하기 때문에 더 이상 아키텍처를 머릿속에 담아두지 않는다. 테스트가 통과되기 때문에 엣지 케이스를 생각하기를 멈춘다. 프롬프트하고 승인하는 것이 더 쉽기 때문에 더 이상 깊이 파고드는 것을 **원하지** 않는다. 더 이상 당신 안에 불꽃이 없다.

[이미지 참고: AI가 생성한 계획과 PR을 검토 없이 '계획 수락'을 누르는 개발자들을 "버터 로봇(butter robot)"으로 묘사하는 밈]

우리 시대의 가장 야심찬 개발자 중 한 명인 사이먼 윌리슨(Simon Willison)은 이것이 이미 자신에게 일어나고 있다고 인정했다. 구현을 검토하지 않고 전체 기능을 프롬프트한 프로젝트에서, 그는 "더 이상 무엇을 할 수 있고 어떻게 작동하는지에 대한 확고한 정신 모델을 갖고 있지 않다"고 했다.

그리고 어느 날, 지표들이 미끄러지기 시작한다… 도구가 나빠진 것이 아니라 당신이 나빠졌기 때문에. 노력의 부족 때문이 아니라, 연습의 부족 때문에. 그렇게 보이지 않을 때까지 진전처럼 보이는 피드백 루프다.

어떤 임원도 이것을 측정하고 싶어하지 않는다. "18개월에 걸친 AI 사용이 엔지니어들의 인지 능력에 미치는 영향은 무엇인가?"는 쉬운 KPI가 아니다. 분기별 리뷰에 맞지 않는다. 추적되지 않고, 추적되지 않는 것은 관리되지 않는다. 팀의 누구도 에이전트 없이 디버깅할 수 없고, 에이전트도 디버깅할 수 없는 프로덕션 인시던트로 나타날 때까지.

나는 AI를 반대하지 않는다. 오히려 좋아한다. 나는 프롬프팅에 중독됐고, 그것으로 흥분한다. 다만 이 새로운 의존이 시간이 지남에 따라, 조용히, 그리고 아무도 그것을 주목하지 않는 사이에 우리를 저하시킬까봐 걱정된다.

---

*이 글은 [Hacker News에서 토론됩니다](https://news.ycombinator.com/item?id=47194847).*

---

Twitter | GitHub | LinkedIn
