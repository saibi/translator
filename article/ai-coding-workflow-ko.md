# 출처 및 번역 정보
- **원문 URL:** https://addyosmani.com/blog/ai-coding-workflow/
- **번역:** Cursor AI (기술 문서 번역)

---

# 2026년을 맞이하는 나의 LLM 코딩 워크플로

## 2026년 1월 4일

**2025년 AI 코딩 어시스턴트는 게임 체인저가 됐지만, 효과적으로 쓰려면 기술과 구조가 필요하다.** 이 도구들은 LLM이 실제 코딩에서 할 수 있는 일을 크게 늘렸고, 많은 개발자(나 포함)가 받아들였다.

예를 들어 Anthropic에서는 엔지니어들이 Claude Code를 그렇게 많이 써서 **오늘 Claude Code 코드의 약 90%가 Claude Code 자체로 작성된다.** 그런데 LLM을 프로그래밍에 쓰는 건 버튼 하나 누르는 마법 같은 경험이 아니다. “어렵고 직관에 반한다”고 느껴지고, 좋은 결과를 내려면 새로운 패턴을 배워야 한다. 비판적 사고는 여전히 핵심이다. 1년 넘게 여러 프로젝트를 하면서 나는 많은 숙련된 개발자들이 발견하는 것과 비슷한 워크플로로 수렴했다. LLM을 **명확한 방향, 컨텍스트, 감독이 필요한** 강력한 페어 프로그래머로 대하되, 자율적 판단을 맡기지 않는 것이다.

이 글에서는 2026년을 맞으며 내가 AI와 어떻게 계획하고, 코딩하고, 협업하는지 공유하고, 내 경험과 커뮤니티의 집단 학습에서 나온 팁과 모범 사례를 정리한다. 더 절제된 **“AI 지원 엔지니어링”** 접근이다. AI를 적극 활용하되 **만들어낸 소프트웨어에 대해 책임은 당당히 내가 진다.**

워크플로에 대해 더 알고 싶다면 “The AI-Native Software Engineer”를 참고하고, 여기서는 내가 배운 교훈 몇 가지로 바로 들어가자.

---

## **명확한 계획으로 시작하기 (코드 전에 스펙)**

**LLM에게 소원만 던지지 말고, 문제를 정의하고 해결책을 계획하는 것부터 시작하라.**

흔한 실수는 모호한 프롬프트로 바로 코드 생성에 뛰어드는 것이다. 내 워크플로와 많은 이들의 워크플로에서 첫 단계는 **AI와 함께 상세 스펙을 브레인스토밍**하고, 단계별 계획을 세운 **뒤에** 실제 코드를 쓰는 것이다. 새 프로젝트에서는 아이디어를 설명하고, 요구사항과 엣지 케이스를 채울 때까지 LLM에게 **반복해서 질문하라**고 요청한다. 마지막에 이걸 종합한 **spec.md**를 만든다. 요구사항, 아키텍처 결정, 데이터 모델, 테스트 전략까지 담는다. 이 스펙이 개발의 기반이 된다.

다음으로 스펙을 추론 가능한 모델에 넣고 **프로젝트 계획을 생성**하라고 프롬프트한다. 구현을 논리적이고 한 입 크기 작업·마일스톤으로 나누게 한다. AI는 사실상 미니 “디자인 문서”나 프로젝트 계획을 도와주는 셈이다. 나는 이 계획을 자주 반복해서 수정하고, AI에게 비판하거나 다듬으라고 요청해, 일관되고 완전해질 때까지 한다. **그 다음에야** 코딩으로 넘어간다. 이 선행 투자는 느리게 느껴질 수 있지만 보상이 크다. Les Orchard 말대로 **“15분 만에 하는 워터폴”**이다. 빠른 구조화된 계획 단계가 이후 코딩을 훨씬 매끄럽게 만든다.

명확한 스펙과 계획이 있으면 코드 생성에 들어갈 때 사람과 LLM 모두 우리가 무엇을, 왜 만드는지 정확히 안다. 요약하면 **먼저 계획하기**가 당신과 AI를 같은 페이지에 두고 낭비되는 사이클을 막는다. 건너뛰고 싶은 단계지만, 숙련된 LLM 개발자들은 이제 견고한 스펙/계획을 워크플로의 초석으로 삼는다.

---

## **작은 반복 단위로 나누기**

**범위 관리가 전부다. LLM에는 한 번에 다루기 쉬운 작업만 주고, 전체 코드베이스를 한꺼번에 주지 마라.**

중요한 교훈은 AI에게 크고 일괄적인 산출을 요청하지 않는 것이다. 대신 **프로젝트를 반복 단계나 티켓으로 나누어** 하나씩 처리한다. 좋은 소프트웨어 엔지니어링 관행과 같지만, AI가 끼어 있을 때는 더 중요하다. LLM은 집중된 프롬프트를 받을 때 가장 잘한다. 한 번에 함수 하나 구현, 버그 하나 수정, 기능 하나 추가. 예를 들어 계획 후 코드 생성 모델에 “계획의 1단계를 구현하자”라고 프롬프트한다. 구현하고 테스트한 뒤 2단계로 넘어가는 식이다. 각 덩어리는 AI가 컨텍스트 안에서 처리할 수 있고 당신이 생성된 코드를 이해할 수 있을 만큼 작다.

이렇게 하면 모델이 선을 이탈하는 것을 막을 수 있다. 한 번에 너무 많이 요청하면 혼란스러워하거나 풀기 어려운 **“뒤섞인 덩어리”**를 만들 가능성이 크다. 개발자들은 LLM에게 앱의 큰 부분을 생성하게 했을 때 일관성 없음과 중복—“서로 말도 안 하고 10명이 작업한 것 같다”는 식—으로 끝났다고 보고한다. 나도 그 고통을 겪었다. 해결책은 **멈추고, 되돌리고, 문제를 더 작은 조각으로 나누는 것**이다. 매 반복에서 지금까지 만든 것의 컨텍스트를 이어가며 점진적으로 더한다. **테스트 주도 개발(TDD)** 접근과도 잘 맞는다. 각 조각마다 테스트를 쓰거나 생성할 수 있다(테스트는 곧 다시 다룬다).

여러 코딩 에이전트 도구가 이제 이 청크 단위 워크플로를 명시적으로 지원한다. 예를 들어 각 작업에 대한 프롬프트 시퀀스를 담은 구조화된 **“프롬프트 계획”** 파일을 만들어, Cursor 같은 도구가 하나씩 실행하게 한다. 요점은 **큰 도약을 피하는 것**이다. 작은 루프로 반복하면 치명적 오류 가능성을 크게 줄이고 빠르게 방향을 잡을 수 있다. LLM은 빠르고 제한된 작업에 강하다. 그걸 활용하라.

---

## **풍부한 컨텍스트와 가이드 제공**

**LLM은 제공한 컨텍스트만큼만 좋다. 관련 코드, 문서, 제약을 _보여주라._**

코드베이스로 작업할 때 **AI가 잘 수행하는 데 필요한 정보를 모두 넣어준다.** 수정하거나 참조해야 할 코드, 프로젝트의 기술적 제약, 알려진 함정이나 선호하는 접근법을 포함한다. 현대 도구가 도와준다. 예를 들어 Anthropic의 Claude는 “Projects” 모드에서 GitHub 저장소 전체를 컨텍스트로 가져올 수 있고, Cursor나 Copilot 같은 IDE 어시스턴트는 열린 파일을 프롬프트에 자동으로 포함한다. 하지만 나는 더 나아간다. Context7 같은 MCP를 쓰거나, 모델이 가지고 있지 않을 것 같으면 코드베이스나 API 문서의 중요한 부분을 대화에 수동으로 복사해 넣는다.

숙련된 LLM 사용자들은 이 “컨텍스트 패킹” 단계를 강조한다. 예를 들어 코딩 전에 모델이 알아야 할 모든 것을 **“브레인 덤프”**로 넣는다. 상위 목표와 불변 조건, 좋은 해법 예시, 피해야 할 접근에 대한 경고를 포함한다. 까다로운 해법을 AI에게 구현하게 할 때는 어떤 단순한 해법이 너무 느린지 알려주거나, 다른 곳의 참조 구현을 줄 수 있다. 틈새 라이브러리나 새 API를 쓸 때는 공식 문서나 README를 붙여넣어 AI가 맹목적으로 동작하지 않게 한다. 이렇게 미리 넣어준 컨텍스트가 산출 품질을 크게 올린다. 모델이 추측하지 않고, 사실과 제약이 앞에 있기 때문이다.

컨텍스트 패킹을 자동화하는 유틸리티도 있다. **gitingest**나 **repo2txt** 같은 도구를 써봤다. 코드베이스의 관련 부분을 **LLM이 읽을 텍스트 파일로 “덤프”**하는 식이다. 큰 프로젝트를 다룰 때 생명줄이 된다. 핵심 소스 파일 묶음으로 output.txt를 만들고 모델이 읽게 한다. 원칙은 **AI가 부분 정보만으로 동작하게 하지 않는 것**이다. 버그 수정에 네 개 모듈 이해가 필요하면 그 네 모듈을 보여준다. 토큰 한도는 봐야 하지만, 최신 프론티어 모델은 꽤 큰 컨텍스트 창(수만 토큰)을 가진다. 잘 활용하라. 나는 보통 당면 작업과 관련된 코드 부분만 선택적으로 넣고, 범위 밖인 것은 AI에게 _집중하지 말라_고 명시해 토큰을 아낀다.

**Claude Skills**는 잠재력이 있다고 생각한다. 깨지기 쉬운 반복 프롬프트를 **지속 가능하고 재사용 가능한 것**으로 바꾼다. 지시, 스크립트, 도메인 전문 지식을 모듈화된 역량으로 묶어서, 요청이 Skill과 맞을 때 도구가 자동으로 적용하게 한다. 그래서 일반적인 프롬프트보다 더 안정적이고 컨텍스트를 아는 결과를 얻고, 일회성 상호작용에서 벗어나 반복 가능한 절차와 팀 지식을 일관되게 인코딩한 워크플로로 간다. 커뮤니티가 만든 Skills 모음도 여러 개 있지만, LLM이 만든 UI에 흔한 보라색 디자인 미학을 “끝낼” 수 있는 frontend-design 스킬이 좋은 예다. 더 많은 도구가 Skills를 공식 지원할 때까지 우회 방법이 있다.

마지막으로 **프롬프트 안의 주석과 규칙으로 AI를 유도**한다. 코드 스니펫 앞에 “X의 현재 구현이다. Y를 하도록 확장해야 하는데 Z를 깨지 않게 주의하라” 같은 문장을 둘 수 있다. 이런 작은 힌트가 크게 도움이 된다. LLM은 **문자 그대로 따르는** 존재다. 지시를 따르니까 상세하고 맥락 있는 지시를 주라. 컨텍스트와 가이드를 적극 제공하면 환각과 엉뚱한 제안을 줄이고 프로젝트에 맞는 코드를 얻는다.

---

## **적절한 모델 선택 (필요하면 여러 개 사용)**

**코딩용 LLM은 다 똑같지 않다. 의도적으로 도구를 고르고, 중간에 모델을 바꾸는 것도 두려워하지 마라.**

2025년에는 다양한 코드 중심 LLM 덕분에 선택이 넓다. 내 워크플로의 일부는 **각 작업에 가장 맞는 모델이나 서비스를 고르는 것**이다. 같은 문제를 서로 다르게 접근하는지 교차 검증하려고 두 개 이상의 LLM을 병렬로 써보는 것도 가치 있을 수 있다.

모델마다 “성향”이 다르다. 요점은 **한 모델이 막히거나 평범한 결과만 내면 다른 걸 써보라**는 것이다. 나는 말 그대로 같은 프롬프트를 한 채팅에서 다른 서비스로 복사해 더 잘 처리하는지 본다. 이 “모델 돌림판”이 모델의 맹점에 걸렸을 때 구원이 된다.

가능하면 **최신 “프로” 티어 모델**을 써라. 품질이 중요하다. 비용이 들더라도 생산성 향상이 정당화할 수 있다. 결국 **“분위기”가 맞는** AI 페어 프로그래머를 고르면 된다. 어떤 사람은 응답이 _느껴지는_ 방식이 마음에 들어 한 모델을 선호한다. 그건 타당하다. AI와 사실상 끊임없이 대화할 때 UX와 톤이 차이를 만든다.

개인적으로 요즘 많은 코딩 작업에 Gemini를 쓰는 편이다. 상호작용이 더 자연스럽고 요청을 한 번에 이해하는 경우가 많다. 하지만 필요하면 다른 모델로 바꾸는 것도 망설이지 않는다. 두 번째 의견이 해법을 찾게 해주는 경우도 있다. 요약하면 **작업에 맞는 최고의 도구를 쓰고, 여러 AI를 무기로 쓸 수 있다는 걸 기억하라.**

---

## **생명주기 전반에서 AI 코딩 활용**

**SDLC 전반에 걸쳐 코딩 특화 AI 도움으로 워크플로를 강화하라.**

커맨드라인에서는 새로운 AI 에이전트가 등장했다. **Claude Code**, **OpenAI의 Codex CLI**, **Google의 Gemini CLI**는 프로젝트 디렉터리에서 직접 대화할 수 있는 CLI 도구다. 파일을 읽고, 테스트를 실행하고, 다단계로 이슈를 수정할 수 있다. Google의 **Jules**와 GitHub의 **Copilot Agent**도 써봤다. **비동기 코딩 에이전트**로, 저장소를 클라우드 VM에 복제해 백그라운드에서 작업(테스트 작성, 버그 수정, PR 생성)한다. “X를 위해 결제 모듈 리팩터해줘” 같은 명령을 내리면 조금 뒤 코드 변경과 통과한 테스트가 담긴 풀 리퀘스트가 오는 걸 보면 약간 섬뜩하다. 우리는 정말 미래에 살고 있다. conductors to orchestrators에서 더 읽을 수 있다.

다만 **이 도구들은 완벽하지 않고, 한계를 이해해야 한다.** 보일러플레이트 생성, 반복 변경 적용, 테스트 자동 실행 같은 기계적 부분을 가속해 주지만, 당신의 가이드가 있으면 훨씬 잘 한다. 예를 들어 Claude나 Copilot 같은 에이전트로 뭔가 구현할 때, 이전 단계의 계획이나 할 일 목록을 넣어서 정확한 작업 순서를 알려준다. 에이전트가 지원하면 실행하라고 하기 전에 spec.md나 plan.md를 컨텍스트에 올린다. 그러면 궤도에 있게 된다.

**AI 에이전트가 통째 기능을 무인으로 코딩하고 완벽한 결과를 기대하는 단계는 아니다.** 대신 나는 이 도구들을 감독하에 쓴다. 코드를 생성하고 실행하게 하되, 각 단계를 지켜보고 뭔가 어긋나면 개입할 준비를 한다. **Conductor** 같은 오케스트레이션 도구로 여러 에이전트를 서로 다른 작업에 병렬로 돌릴 수 있다(AI 도움을 확장하는 방식). 3~4개 에이전트를 동시에 별도 기능에 돌리는 실험을 하는 엔지니어도 있다. 나도 이 “대규모 병렬” 접근을 해봤다. 빠르게 많이 해치우는 데는 놀랍도록 효과적이지만, 여러 AI 스레드를 모니터하는 건 정신적으로 부담된다. 대부분은 한 번에 메인 에이전트 하나와, 리뷰용 보조 하나 정도만 쓴다(아래에서 다룸).

이건 파워 툴이라는 걸 기억하라. 트리거를 당기는 것과 결과를 이끄는 건 여전히 당신이다.

---

## **사람을 루프에 두기 — 검증·테스트·리뷰**

**AI는 그럴듯해 보이는 코드를 기꺼이 만들지만, 품질에 대한 책임은 _당신_에게 있다. 항상 꼼꼼히 리뷰하고 테스트하라.**

내 핵심 규칙 중 하나는 LLM 출력을 맹목적으로 믿지 않는 것이다. Simon Willison 말대로 LLM 페어 프로그래머를 **“과신하고 실수하기 쉬운”** 존재로 생각하라. 버그나 말도 안 되는 것까지 완전한 확신으로 코드를 쓰고, 당신이 찾아내기 전까지 뭔가 잘못됐다고 말하지 않는다. 그래서 AI가 만든 스니펫은 주니어 개발자가 쓴 것처럼 대한다. 코드를 읽고, 실행하고, 필요하면 테스트한다. **쓴 코드는 반드시 테스트해야 한다.** 유닛 테스트를 돌리거나 기능을 수동으로 실행해 주장한 대로 동작하는지 확인하라. vibe coding is not an excuse for low-quality work에서 더 읽을 수 있다.

사실 나는 테스트를 워크플로 자체에 짜 넣는다. 앞선 계획 단계에 각 단계에 대한 테스트 목록이나 테스트 계획 생성이 들어가는 경우가 많다. Claude Code 같은 도구를 쓸 때는 작업 구현 후 테스트 스위트를 실행하라고 하고, 실패하면 디버깅하라고 한다. 이렇게 타이트한 피드백 루프(코드 작성 → 테스트 실행 → 수정)는 **테스트가 있을 때** AI가 잘한다. 코딩 에이전트를 가장 잘 쓰는 사람들이 테스트 관행이 탄탄한 사람들이라는 건 당연하다. Claude 같은 에이전트는 좋은 테스트 스위트가 안전망이면 프로젝트를 “날아다닌다”. 테스트가 없으면 에이전트는 여러 걸 부숴놓고도 “네, 다 괜찮아요!”라고 가볍게 넘길 수 있다. 그래서 **테스트에 투자하라.** AI의 유용성과 결과에 대한 신뢰가 커진다.

자동화된 테스트를 넘어 **코드 리뷰—수동이든 AI 보조든—를 하라.** 나는 지금까지 생성된 코드를 줄마다 리뷰하곤 한다. 두 번째 AI 세션(또는 다른 모델)을 띄워서 첫 번째가 만든 코드를 비판·리뷰하게 할 때도 있다. 예를 들어 Claude로 코드를 쓰게 하고 Gemini에게 “이 함수에 오류나 개선점이 있나 리뷰해줘”라고 할 수 있다. 미묘한 문제를 잡을 수 있다. 요점은 AI가 코드를 썼다고 해서 리뷰를 건너뛰지 않는 것이다. 오히려 AI가 쓴 코드는 **더 꼼꼼히 봐야** 한다. 표면적으로는 그럴듯한데 사람이 바로 눈치채기 어려운 결함을 숨길 수 있기 때문이다.

디버깅과 품질 루프를 위해 이전 팀과 만든 **Chrome DevTools MCP**도 쓴다. 정적 코드 분석과 실제 브라우저 실행 사이 간극을 메운다. “에이전트에게 눈을 준다.” AI 도구가 브라우저가 보는 것을 직접 볼 수 있게 하고, DOM을 검사하고, 성능 트레이스·콘솔 로그·네트워크 트레이스를 얻을 수 있게 한다. 이 통합으로 수동 컨텍스트 전환 마찰이 없어지고, LLM을 통해 UI 테스트를 자동으로 할 수 있다. 실제 런타임 데이터로 버그를 정확히 진단하고 수정할 수 있다는 뜻이다.

사람 감독을 건너뛰었을 때의 심각한 결과도 보고됐다. 급한 프로젝트에서 AI 생성에 크게 의존한 한 개발자는 결과를 일관성 없는 난장판—중복 로직, 안 맞는 메서드 이름, 일관된 아키텍처 없음—이라고 했다. AI가 엮어 놓은 것을 제대로 보지 않고 “만들고, 만들고, 만들기”만 했다는 걸 깨달았다. 고통스러운 리팩터와, 다시는 그렇게 손을 놓지 않겠다는 다짐이 필요했다. 나는 그걸 마음에 새긴다. **AI를 얼마나 쓰든, 책임지는 엔지니어는 나다.**

실무적으로는 이해한 뒤에만 머지하거나 배포한다. AI가 복잡한 걸 만들면 설명 주석을 달라고 하거나, 더 단순한 표현으로 다시 쓴다. 뭔가 이상하면 파고든다. 인간 동료가 위험 신호를 주는 코드를 기여했을 때와 똑같이.

전부 마인드셋이다. **LLM은 어시스턴트이지, 자율적으로 믿을 수 있는 코더가 아니다.** 시니어는 나고, LLM은 나를 가속시키는 존재이지 내 판단을 대체하는 게 아니다. 이 자세를 유지하면 더 나은 코드가 나오고, 개발자로서의 성장도 지킨다. (AI에 너무 의존하면 실력이 둔해진다는 우려도 있는데, 루프에 남아서 적극적으로 모든 걸 리뷰하고 이해하면 본능은 더 날카로워진다. 속도만 더 빨라질 뿐이다.) 요약하면 **경계하고, 자주 테스트하고, 항상 리뷰하라.** 결국 당신 코드베이스다.

---

## **자주 커밋하고 버전 관리로 안전망 삼기. 설명할 수 없는 코드는 커밋하지 마라.**

**자주 커밋하면 세이브 포인트가 된다. AI가 잘못한 걸 되돌리고 변경을 이해할 수 있다.**

많은 코드를 빠르게 생성하는 AI와 작업하면 방향이 쉽게 어긋난다. 나는 초세밀한 버전 관리 습관으로 완화한다. 평소 손코딩보다 더 일찍, 더 자주 커밋한다. 작은 작업 하나나 자동 편집이 성공할 때마다 명확한 메시지로 git 커밋을 한다. 그러면 AI의 다음 제안이 버그나 지저분한 변경을 넣어도 되돌리거나 체리픽할 최근 체크포인트가 있어서 몇 시간을 잃지 않는다. 한 실무자는 커밋을 **“게임의 세이브 포인트”**처럼 대하라고 했다. LLM 세션이 삐끗하면 마지막 안정 커밋으로 롤백할 수 있다. 그 조언이 매우 유용했다. 필요하면 git reset으로 되돌릴 수 있다는 걸 알면 대담한 AI 리팩터 실험이 훨씬 덜 스트레스다.

버전 관리는 AI와 협업할 때도 도움이 된다. AI가 한 일을 다 기억한다고 믿을 수 없으니(컨텍스트 창 한도 등) git 히스토리가 소중한 로그가 된다. 최근 커밋을 훑어서 AI(또는 나)에게 무엇이 바뀌었는지 브리핑할 때가 많다. 사실 LLM에게 커밋 히스토리를 주면 활용할 수 있다. git diff나 커밋 로그를 프롬프트에 붙여넣어 새 코드나 이전 상태를 알려준다. 재미있게도 LLM은 diff 파싱과 git bisect 같은 도구로 버그가 어디서 들어왔는지 찾는 데 **정말** 능하다. 커밋 히스토리를 끝없이 탐색하는 인내심이 있어서 디버깅을 보강할 수 있다. 다만 깔끔한 커밋 히스토리가 있을 때만 그렇다.

또 다른 이점은, 좋은 메시지가 달린 작은 커밋이 개발 과정을 문서화해서 코드 리뷰(AI든 사람이든)에 도움이 된다는 것이다. AI 에이전트가 한 번에 다섯 가지를 바꿨는데 뭔가 깨졌다면, 변경을 커밋별로 나누어 두면 어떤 커밋이 원인인지 좁히기 쉽다. “AI changes”라는 거대한 커밋 하나에 다 들어 있으면 운에 맡기자. 그래서 스스로 훈련한다. _작업 끝내기, 테스트 실행, 커밋._ 이건 작업을 작은 덩어리로 나누라는 앞선 팁과도 잘 맞는다. 각 덩어리가 결국 자기 커밋이나 PR이 된다.

마지막으로 AI 실험을 격리하려고 **브랜치나 워크트리**를 쓰는 것을 두려워하지 마라. Jesse Vincent 같은 사람들에 영감 받아 쓰는 고급 워크플로는 새 기능이나 하위 프로젝트마다 새 git worktree를 띄우는 것이다. 같은 저장소에서 여러 AI 코딩 세션을 서로 방해하지 않고 병렬로 돌리고, 나중에 변경을 머지할 수 있다. 각 AI 작업을 자체 샌드박스 브랜치에 두는 것과 비슷하다. 한 실험이 실패하면 그 워크트리를 버리고 main에는 손실이 없다. 성공하면 머지한다. AI가 기능 A를 구현하는 동안 나(또는 다른 AI)가 기능 B를 동시에 작업할 때 이 접근이 중요했다. 버전 관리 덕분에 이 조율이 가능하다. 요약하면 **자주 커밋하고, 브랜치로 작업을 정리하고, git을 AI 생성 변경을 다루기 쉽고 되돌릴 수 있게 하는 제어 수단으로 받아들이라.**

---

## **규칙과 예시로 AI 동작 맞추기**

**스타일 가이드, 예시, “규칙 파일”까지 주어 AI 어시스턴트를 조종하라. 조금만 미리 튜닝해도 결과가 훨씬 나아진다.**

AI의 기본 스타일이나 접근을 그대로 받아들일 필요는 없다. 가이드라인을 주면 크게 영향을 준다. 예를 들어 **CLAUDE.md** 파일을 주기적으로 갱신한다. Claude(Anthropic 모델)가 따를 프로세스 규칙과 선호를 담는다(Gemini CLI 쓸 때는 GEMINI.md도 비슷하게). “프로젝트 스타일로 코드 작성, 린트 규칙 따르기, 특정 함수 사용 금지, OOP보다 함수형 스타일 선호” 같은 것들이다. 세션을 시작할 때 이 파일을 Claude에 넣어 우리 관례에 맞춘다. Jesse Vincent가 말한 대로 모델을 “궤도에” 두는 데 얼마나 잘 먹히는지 놀랍다. AI가 스크립트에서 벗어나거나 원하지 않는 패턴을 넣는 경향이 줄어든다.

멋진 규칙 파일 없이도 **커스텀 지시나 시스템 프롬프트로 톤을 정할** 수 있다. GitHub Copilot과 Cursor 모두 프로젝트 전역으로 AI 동작을 설정하는 기능을 도입했다. 코딩 스타일에 대한 짧은 문단을 써서 활용한다. “들여쓰기 4칸, React에서 화살표 함수 피하기, 설명적인 변수명 선호, ESLint 통과” 같은 식이다. 이 지시가 있으면 AI 제안이 인간 팀원이 쓸 법한 것에 훨씬 가까워진다. Ben Congdon은 **Copilot 커스텀 지시**를 쓰는 사람이 얼마나 적은지, 효과를 생각하면 충격이라고 했다. 예시와 선호를 미리 주면 팀의 관용구에 맞는 코드를 내게 유도할 수 있다고. 나도 동의한다. AI에게 기대를 가르치는 시간을 들여라.

또 한 가지 강력한 방법은 원하는 산출 형식이나 접근의 **인라인 예시**를 주는 것이다. AI가 아주 구체적인 방식으로 함수를 쓰게 하려면, 먼저 코드베이스에 있는 비슷한 함수를 보여줄 수 있다. “X는 이렇게 구현했고, Y도 비슷하게 해줘.” 주석 스타일을 정하고 싶으면 내가 주석을 하나 쓰고 그 스타일로 이어가라고 할 수 있다. 요약하면 따라할 패턴으로 모델을 _프라이밍_하는 것이다. LLM은 모방에 강하다. 한두 개 예시를 보여주면 그 흐름으로 이어간다.

커뮤니티는 LLM 동작을 다스리기 위한 창의적인 “규칙셋”도 만들어냈다. “Big Daddy” 규칙이나 프롬프트에 “환각/기만 금지” 조항을 넣는 걸 들어봤을 것이다. AI에게 진실하게 하고 존재하지 않는 코드를 지나치게 만들어내지 말라고 상기시키는 트릭이다. 예를 들어 프롬프트 앞에 “뭔가 확실하지 않거나 코드베이스 컨텍스트가 부족하면 답을 만들어내지 말고 명확히 해달라고 요청하라”를 붙인다. 환각이 줄어든다. 또 쓰는 규칙은 “버그 수정 시 주석으로 추론을 짧게 설명하라”다. 그러면 AI가 수정을 만들 때 “// 수정: Z를 방지하기 위해 X를 Y로 변경(스펙 기준)” 같은 주석을 남긴다. 나중 리뷰에 매우 유용하다.

요약하면 **AI를 블랙박스처럼 대하지 말고 튜닝하라.** 시스템 지시 설정, 프로젝트 문서 공유, 명시적 규칙 작성으로 AI를 팀의 더 전문적인 개발자처럼 만든다. 신입 온보딩과 비슷하다. 스타일 가이드와 팁을 주지 않겠는가? AI 페어 프로그래머에게도 그렇게 하라. 투자 대비 효과는 크다. 손댈 게 적고 코드베이스와 더 잘 어울리는 결과를 얻는다.

---

## **테스트와 자동화를 증폭기로 활용**

**CI/CD, 린터, 코드 리뷰 봇을 써라. AI는 실수를 자동으로 잡는 환경에서 가장 잘 동작한다.**

루프에 남고 컨텍스트를 제공하는 것의 따름정리다. 잘 돌아가는 개발 파이프라인이 AI 생산성을 높인다. AI 코딩을 많이 쓰는 저장소에는 견고한 **지속적 통합(CI)** 구성을 갖추도록 한다. 모든 커밋이나 PR에서 자동 테스트가 돌고, 코드 스타일 검사(ESLint, Prettier 등)가 적용되고, 가능하면 새 브랜치마다 스테이징 배포가 있게 한다. 왜? AI가 이걸 트리거하고 결과를 평가하게 할 수 있기 때문이다. 예를 들어 Jules나 GitHub Copilot Agent로 AI가 풀 리퀘스트를 열면 우리 CI가 테스트를 돌리고 실패를 보고한다. 그 실패 로그를 AI에 다시 넣을 수 있다. “통합 테스트가 XYZ로 실패했어, 이걸 디버깅하자.” 버그 수정이 빠른 피드백이 있는 협업 루프가 되고, AI가 꽤 잘 처리한다(수정 제안 → CI 다시 실행 → 반복).

자동 코드 품질 검사(린터, 타입 체커)도 AI를 유도한다. 나는 가끔 린터 출력을 프롬프트에 넣는다. AI가 린터를 통과하지 못하는 코드를 쓰면 린터 오류를 채팅에 복사해 “이 이슈들을 해결해줘”라고 한다. 그러면 모델이 정확히 뭘 해야 할지 안다. AI 옆에서 엄격한 선생님이 지켜보는 것과 같다. 내 경험상 AI가 도구 출력(실패한 테스트, 린트 경고)을 알면 매우 열심히 고치려 한다. “올바른 답”을 내고 싶어 하니까. 이건 컨텍스트 제공으로 다시 이어진다. 환경에서의 행동 결과(테스트 실패 등)를 AI에게 주면 그걸로 학습한다.

AI 코딩 에이전트 자체도 자동화 훅을 점점 더 넣고 있다. 어떤 에이전트는 모든 테스트가 통과할 때까지 코드 작업이 “완료”라고 말하지 않는다. 원하는 바로 그 성실함이다. 코드 리뷰 봇(AI든 아니든)은 또 다른 필터다. 그 피드백을 개선을 위한 추가 프롬프트로 본다. 예를 들어 CodeRabbit이나 다른 리뷰어가 “이 함수가 X를 하는데 이상적이지 않다”고 하면 AI에게 “이 피드백으로 리팩터해줄 수 있어?”라고 한다.

AI와 자동화를 결합하면 선순환이 생긴다. AI가 코드를 쓰고, 자동 도구가 이슈를 잡고, AI가 고치고, 당신이 상위 방향을 감독한다. 매우 빠른 주니어 개발자에게 지칠 줄 모르는 QA 엔지니어가 즉시 검사하는 느낌이다. 하지만 그 환경을 _당신이_ 만든다. 테스트나 자동 검사가 없으면 AI 작업이 미묘한 버그나 낮은 품질로 나중까지 그대로 통과할 수 있다.

2026년을 맞으며 목표 중 하나는 AI 코드 기여 주변 품질 게이트를 강화하는 것이다. 더 많은 테스트, 더 많은 모니터링, AI가 AI 코드를 리뷰하는 것까지. 역설적으로 들릴 수 있지만(AI가 AI를 리뷰) 한 모델이 놓친 걸 잡는 걸 봤다. 결론은 **AI 친화적 워크플로는 강한 자동화가 있는 워크플로다. 그 도구로 AI를 정직하게 유지하라.**

---

## **계속 배우고 적응하기 (AI가 당신 기술을 증폭한다)**

**매 AI 코딩 세션을 학습 기회로 삼아라. 알면 알수록 AI가 더 도와주고, 선순환이 생긴다.**

개발에서 LLM을 쓰는 가장 흥미로운 점 중 하나는 그 과정에서 _나_가 얼마나 많이 배우는지다. 아는 필요를 대체하기보다, AI는 오히려 혼자라면 시도하지 않았을 새 언어, 프레임워크, 기법을 접하게 해줬다.

이 패턴은 일반적이다. 탄탄한 소프트웨어 엔지니어링 기초를 갖고 오면 AI가 당신 생산성을 **여러 배로 증폭**한다. 기초가 없으면 AI가 혼란만 증폭할 수 있다. 숙련된 개발자들은 LLM이 “기존 모범 사례를 보상한다”고 관찰한다. 명확한 스펙 쓰기, 좋은 테스트, 코드 리뷰 같은 것들이 AI가 끼면 더욱 강해진다. 내 경험상 AI는 보일러플레이트를 뽑아내는 동안 나는 더 높은 추상화 수준(설계, 인터페이스, 아키텍처)에서 일하게 해주지만, 그 상위 기술을 먼저 **가져야** 한다. Simon Willison 말대로 **시니어 엔지니어**를 만드는 거의 모든 것(시스템 설계, 복잡성 관리, 무엇을 자동화하고 손코딩할지 아는 것)이 이제 AI와 함께 최고의 결과를 낸다. 그래서 AI를 쓰는 게 오히려 **엔지니어링 수준을 올리게** 했다. 매우 빠르지만 다소 순진한 코더(AI)를 사실상 “관리”하니까 계획에 더 엄격하고 아키텍처를 더 의식하게 됐다.

AI를 쓰면 실력이 떨어질까 걱정하는 사람에게는, 제대로 하면 반대라고 말하고 싶다. AI 코드를 리뷰하면서 새 관용구와 해법을 접했다. AI 실수를 디버깅하면서 언어와 문제 도메인 이해가 깊어졌다. AI에게 코드나 수정 이유를 설명하라고 자주 묻는다. 지원자에게 코드에 대해 계속 면접하는 것처럼. 답에서 통찰을 얻는다. AI를 리서치 어시스턴트로도 쓴다. 라이브러리나 접근이 확실하지 않으면 옵션을 나열하거나 트레이드오프를 비교하게 한다. 백과사전 같은 멘토가 상주하는 것과 같다. 이 모든 게 나를 더 박식한 프로그래머로 만들었다.

큰 그림은 **AI 도구가 당신의 전문성을 증폭한다**는 것이다. 2026년을 맞으며 “내 일자리를 뺏을”까 두렵지 않다. 단조로운 일에서 해방되고 소프트웨어 엔지니어링의 창의적·복잡한 부분에 더 많은 시간을 쓸 수 있어 기쁘다. 하지만 기초가 탄탄하지 않은 사람에게 AI가 스테로이드 맞은 더닝-크루거 효과(훅 하고 무너질 때까지 뭔가 훌륭한 걸 만든 것처럼 _느껴질_ 수 있음)로 이어질 수 있다는 것도 안다. 그래서 조언한다. 기술을 계속 갈고, AI로 그 과정을 가속하라. 날카로움을 유지하려고 가끔 AI 없이 코딩하는 것도 의도적으로 하라. 결국 개발자 + AI 조합이 둘 중 하나만 있을 때보다 훨씬 강하고, 그 조합의 _개발자_ 쪽이 제 몫을 해야 한다.

---

## **결론**

나는 개발 워크플로에 AI를 완전히 받아들였다. 다만 신중하고, 전문가 주도적인 방식으로. 내 접근은 사실상 **“AI 증강 소프트웨어 엔지니어링”**이지 AI 자동화 소프트웨어 엔지니어링이 아니다.

배운 것은 **클래식 소프트웨어 엔지니어링 훈련을 AI 협업에 적용할 때 최고의 결과가 나온다**는 것이다. 코딩 전 설계, 테스트 작성, 버전 관리, 표준 유지 같은 우리의 고생 끝에 얻은 관행들이 AI가 코드의 절반을 쓸 때 오히려 더 중요해진다.

앞으로가 기대된다. 도구는 계속 나아지고 내 워크플로도 함께 진화할 것이다. 완전 자율 “AI 개발 인턴”이 허드렛일을 더 맡고 우리는 상위 작업에 집중할 수도 있다. 디버깅과 코드 탐색의 새 패러다임이 나올 수도 있다. 어찌 됐든 나는 _루프에_ 남아서 AI를 이끌고, 그들에게서 배우고, 생산성을 책임 있게 증폭할 계획이다.

나에게 결론은 이거다. **AI 코딩 어시스턴트는 놀라운 증폭기지만, 연출은 여전히 인간 엔지니어가 한다.**

_O’Reilly와 함께한 AI 지원 엔지니어링 책을 새로 냈다. 관심 있으면 책 사이트에 무료 팁이 여러 개 있다._

Addy Osmani는 Google에서 Google Cloud와 Gemini를 담당하는 소프트웨어 엔지니어다.
