소스 URL: https://shumer.dev/gpt53-codex-review
번역 모델: Gemini 2.0 Flash

# 나의 GPT-5.3-Codex 리뷰 — Matt Shumer

## 완전한 자율성이 도래하다
**작성자: Matt Shumer • 2026년 2월 5일**

---

### 요약 (TL;DR)
- 이 모델은 작업을 시작해두고 몇 시간 동안 자리를 비웠다 돌아와도 완벽하게 작동하는 소프트웨어를 결과물로 내놓는 최초의 코딩 모델입니다. 8시간 이상의 긴 작업도 경로를 이탈하지 않고 수행하는 것을 확인했습니다.
- 가장 큰 업그레이드는 **모호함 속에서의 판단력**입니다. 프롬프트에 세부 사항이 누락되었을 때, 모델이 내리는 가정이 놀랍게도 제가 직접 결정했을 법한 내용과 일치합니다.
- **테스트와 검증(Validation)** 기능이 엄청난 전환점이 되었습니다. 명확한 통과/실패 목표가 주어지면, 모델은 방향을 잃지 않고 수 시간 동안 반복(iteration) 작업을 수행합니다.
- Opus 4.5보다 속도는 느리지만, 자율성 측면에서는 훨씬 뛰어납니다.
- **멀티 에이전트 협업**이 마침내 실질적으로 느껴집니다.
- 이 정도 수준의 자율성이 어떤 느낌인지 직접 시도해보지 않고는 상상하기 어렵습니다. 한 번 경험하고 나면 다른 모델로 돌아가기 힘들 것입니다.

### 장점 (The Good)
- 전체 수명 주기의 루프를 스스로 닫을 수 있습니다. 코드 변경, 푸시, 배포, 라이브 URL 확인, 서버 로그 모니터링을 수행하며 실제로 작동할 때까지 반복 작업을 계속합니다. 거의 매번 성공합니다.
- 프롬프트에 중요한 세부 사항이나 아키텍처 결정이 누락되었을 때, 놀라울 정도로 제 개인적인 판단과 유사한 가정을 내립니다.
- 몇 시간 동안 지속되는 작업 중에도 성능이 저하되거나 혼란을 겪지 않습니다. 제약 조건이 충족될 때까지 계속 밀어붙입니다.
- 코드 품질이 경쟁 모델보다 훨씬 뛰어납니다. 아키텍처가 더 깔끔하고, 임시방편(hacky) 패치가 적으며, 시간이 지나면서 쌓이는 미묘한 버그도 적습니다.
- 유휴 시간(dead time)을 잘 활용합니다. 무언가 실행 중이라 대기해야 할 때, 스스로 컨텍스트를 수집하거나 문서를 개선하고, 선을 넘지 않는 범위 내에서 인접한 문제를 해결합니다.
- 명시적으로 지시하지 않아도 설치된 도구(skills)를 스스로 찾아내어 사용합니다. 다른 모델들은 보통 "이걸 써봐"라고 힌트를 주어야 합니다.
- "이 장비에서 X를 위한 API를 노출하는 레포지토리를 찾아줘"라고 하면, 이를 찾아내고 패턴을 학습하여 올바르게 적용합니다. 다른 레포지토리에 변경 사항을 푸시하고 돌아와도 흐름을 놓치지 않습니다.
- AgentRelay 하네스를 이용한 멀티 에이전트 테스트에서, 마침내 멀티 에이전트 협업이 실질적으로 작동한다는 느낌을 받았습니다. 단순히 보여주기 식이 아니라, 실제로 결과를 개선하는 유용한 방식으로 협업했습니다.

### 단점 (The Not-So-Good)
- Opus 4.5보다 느립니다. 작업에 수 시간이 걸리는 경우가 많으며, 이는 실제적인 기회비용입니다.
- 프롬프트나 에이전트 아키텍처 설계용으로는 가장 선호하는 모델이 아닙니다. 에이전트를 설계하거나 프롬프트를 다듬을 때는 여전히 Opus를 사용합니다.
- **상태 설명(Status narration)**이 불안정할 때가 있습니다. 작업 중간에 업데이트를 멈추기도 하고, UI의 작업 추적 체크박스가 제때 갱신되지 않아 진행 상황이 불투명해 보일 때가 있습니다.
- 실행 요약이 너무 기술적일 때가 많습니다. 기초 지식이 부족한 '바이브 코더(vibe-coder)'라면 쉬운 영어로 다시 설명해달라고 요청해야 할 것입니다.
- 성능이 너무 뛰어나서 모델이 돌아가는 동안 무엇을 해야 할지 모를 때가 있습니다. 참 묘한 문제입니다.

### 모든 도약은 워크플로우를 변화시키며, 이번 도약은 매우 거대합니다
메이저 모델의 비약적인 발전은 제가 AI 시스템을 사용하는 방식을 매번 바꿉니다. Opus 4.5가 완전한 자율성에 매우 근접했다면, GPT-5.3-Codex는 다음과 같은 느낌을 주는 첫 모델입니다. "결과를 명시하고, 검증 절차(명확한 통과/실패 테스트)를 설정한 뒤 시작 버튼을 누른다... 그리고 한두 시간(또는 그 이상) 뒤에 돌아오면, 아무리 복잡한 작업이라도 거의 완벽하게 완료되어 있을 것이라는 확신이 든다."

불과 1년 반 전의 일이라는 게 믿기지 않지만, Sonnet 3.5는 말 그대로 영어를 코드로 바꿔주는 번역기에 가까웠습니다. 훌륭했지만 모든 단계를 직접 운전해야 했죠. 시키는 대로 (거의) 정확히 수행하는 것은 유용했지만, 스스로 업무를 진전시키지는 못했습니다. 이를 효과적으로 활용하려면 어느 정도 빌드(build)하는 법을 알아야 했습니다.

그 후 모델들은 더 강력해졌습니다. 마치 주니어 엔지니어처럼 느껴지기 시작했죠. 조금 더 큰 작업을 맡길 수 있었고, 더 오랫동안 실행되었습니다. 하지만 여전히 거의 모든 단계에서 손을 잡아줘야 했고, 반복 작업은 끊임없는 싸움이었습니다. 기능을 하나 제대로 완성하려면 10~20개의 프롬프트가 필요했고, 매우 복잡한 경우에는 그 이상이 들기도 했습니다.

GPT-5는 그다음 단계의 거대한 변화였습니다. 저는 단계를 하나씩 떠먹여 주는 것을 멈추고 더 큰 결과물을 요구하기 시작했습니다. 꽤 많은 일을 자율적으로 해낼 수 있었지만, 거대한 레포지토리에서는 여전히 실수를 연발했고, 특히 시간이 지날수록, 그리고 제가 한계까지 밀어붙일수록 실수가 잦아졌습니다. 무엇보다 제가 원하는 방식을 매우 상세하게 설명하는 프롬프트를 주며 어느 정도는 직접 운전해야 했습니다.

우리 모두 알다시피 Opus 4.5는 GPT-5(및 이후 출시된 모델들)로부터 큰 도약을 이루었습니다. Opus 4.5는 미친 듯이 빠르고 제가 던지는 대부분의 일을 훌륭하게 처리하지만, 여전히 매우 엄격한 가드레일이 필요합니다. 제약 조건, 비목표(non-goals), 검증 방식에 대해 극도로 명시적이지 않으면, 모델은 종종 성공을 위한 가장 빠른 길을 선택해 버립니다. 근본 원인을 우회하여 패치하거나, 건드리지 말아야 할 곳을 비워두거나(stub), "견고하고 사용자가 원하는 방식"보다는 "다 된 것처럼 보이게" 만드는 데 최적화하곤 합니다.

제가 명시적으로 지시하더라도, 가끔은 제가 배포하지 않을 방식으로 문제를 해결하기도 합니다. 이런 판단력의 마지막 5~10% 부족함이 길고 지저분하며 중요한 작업에서 드러나게 되고, 결국 나중에 몇 시간을 더 허비하게 만듭니다.

하지만 이제 우리는 다음 단계에 도달했습니다. 감히 말씀드리자면, 이것이 바로 **완전한 자율성**입니다. 우리는 마침내 그곳에 도착했습니다.

### 큰 차이점: 모호함 속에서 제가 내릴 법한 결정을 내립니다
가장 중요한 업그레이드는 속도가 아닙니다. 가공되지 않은 지능도 아닙니다. 바로 **판단력**입니다.

"하지만 Matt!" 여러분은 이렇게 말하겠죠. "판단력은 인간만이 가진 고유한 영역이야!" 죄송하지만 그렇지 않습니다. 특정 분야에 대한 데이터가 존재한다면, 그 데이터로 훈련된 모델도 그 일을 할 수 있다는 것이 점점 더 분명해지고 있습니다. 인간의 판단력은 인터넷상의 방대한 데이터에 이미 존재합니다. 모델 회사들은 판단력과 취향(taste)에 도움을 줄 데이터를 확보하기 위해 막대한 돈을 쏟아붓고 있습니다.

이 모델은 특정 도메인에 대해 그런 판단력을 깊은 수준에서 내재화한 것처럼 느껴지는 첫 번째 모델입니다. 프롬프트에 해석의 여지가 있을 때, GPT-5.3-Codex는 제가 선택했을 법한 방식을 선택하는 경향이 있습니다. 제가 실제로 문제에 대해 생각하는 방식과 일치하는 방향으로 누락된 컨텍스트를 채워 넣습니다.

모호한 상황에서의 가정(Assumption) 품질은 사람들이 생각하는 것보다 훨씬 중요하며, GPT-5.3-Codex는 제가 사용해 본 이전 모델들보다 이 부분에서 훨씬 뛰어납니다.

### 멀티 에이전트 협업이 마침내 실질적으로 느껴집니다
또한 최근 제가 투자한 AgentRelay로 구축한 멀티 에이전트 하네스에서 GPT-5.3-Codex를 테스트해 보았습니다. 여러 개의 GPT-5.3-Codex 인스턴스가 서로 대화하며 문제를 해결하게 했고, 그 결과는 정말 놀라웠습니다. 이에 대해서는 곧 더 자세히 공유할 예정입니다.

이 모델은 다른 모델과 정말로 협업할 수 있는 제가 본 최초의 모델 중 하나이며, 단순히 겉치레가 아닙니다. Opus를 같은 환경에서 테스트했을 때는 "대화를 위한 대화"처럼 느껴질 때가 많았고, 여러 모델을 쓰는 게 실제로 더 나은지 불분명했습니다. 하지만 GPT-5.3-Codex를 사용하면 커뮤니케이션이 효율적이었고, 에이전트들이 스스로 집중된 워크스트림으로 갈라졌으며, 협업을 통해 실제로 더 나은 결과물을 만들어냈습니다. 작업 속도가 훨씬 빨라졌고 각 에이전트는 더 전문화된 상태를 유지했습니다. 정말 대단했습니다. 조만간 이런 방식이 매우 일반화될 것이라고 생각합니다.

### 핵심 열쇠: 검증(Validation)이 이 모델을 진정한 에이전트로 만듭니다
완전한 자율성을 원한다면 다른 모든 것보다 압도적인 한 가지 접근 방식이 있습니다. 바로 모델에 강력한 검증 수단과 테스트를 미리 제공하는 것입니다.

명확한 검증 목표가 있으면 GPT-5.3-Codex는 흐름을 놓치지 않고 수 시간 동안 반복 작업을 수행합니다. 경로를 이탈하지도, 중간에 혼란을 겪지도 않습니다. 제약 조건이 충족되고 테스트가 통과(green)될 때까지 계속 밀어붙입니다. 테스트가 없어도 훌륭하지만, 테스트가 있으면 차원이 다른 도구가 됩니다.

참고로 이는 모든 현대적 코딩 에이전트에 해당되는 사실입니다. 다만 GPT-5.3-Codex는 목표를 향해 반복 작업을 수행할 때 검증과 테스트를 효과적으로 사용하는 능력에서 다른 체급에 속해 있을 뿐입니다.

### 지시하지 않아도 스스로 도구를 사용합니다
이것은 작지만 매우 중요한 세부 사항입니다. 이 모델은 제가 명시적으로 지시하지 않아도 적절한 시점에 로컬 도구와 기술(skills)을 기꺼이 사용합니다. Opus 4.5조차도 종종 "이 일을 위한 도구가 있는지 확인해봐"라는 힌트가 필요합니다. 스스로 무엇이 사용 가능한지 자연스럽게 훑어보지 않기 때문입니다. 반면 GPT-5.3-Codex는 이를 수행하며, 도구가 존재하기 때문이 아니라 실제로 유용할 때만 사용하는 경향이 있습니다.

### 안심하고 자리를 비울 수 있는 첫 번째 모델
장기적이고 까다로운 엔지니어링 작업의 경우, 이 모델은 제가 작업을 시작해두고 계속 모니터링해야 한다는 압박감 없이 다른 일을 하러 갈 수 있는 최초의 모델입니다. 그냥 계속 나아갑니다. 서서히 성능이 저하되지도 않고, 조기에 포기하지도 않습니다. 결국 해냅니다.

네, Opus 4.5보다 느립니다. 작업에 수 시간이 걸리는 경우도 많습니다(8시간 이상 걸린 적도 몇 번 있습니다). 그 기회비용은 매우 실질적입니다. 하지만 안정성이 훨씬 높기 때문에, 정말 틀리고 싶지 않은 작업에 대해서는 이 모델을 더 신뢰하게 됩니다.

### 코드 품질 또한 더 좋아졌습니다
이 부분은 몇 주 후에나 체감할 수 있기 때문에 놓치기 쉽습니다. 코드 품질과 아키텍처가 보통 Opus 4.5에서 얻는 것보다 훨씬 훌륭합니다. 임시방편적인 패치가 적고, 남겨진 쓰레기 코드가 적으며, 레포지토리가 진화하면서 쌓이는 미묘한 버그도 적습니다. 단순히 작업을 완료하는 수준이 아닙니다. 보통 코드베이스를 훨씬 더 나은 상태로 만들어 놓는데, 이는 모델이 훨씬 더 오랫동안 작업하고 더 큰 변경을 수행하는 경우가 많다는 점을 고려하면 매우 인상적입니다.

### 유능한 엔지니어처럼 시간을 활용합니다
과소평가된 또 다른 행동은 유휴 시간을 잘 활용한다는 점입니다. 무언가 실행 중이고 그 순간에 할 수 있는 유용한 일이 딱히 없다면, 모델은 종종 컨텍스트를 수집하거나 문서를 개선하고 스스로 문제를 해결하러 갑니다. 다른 모델들은 제가 다음에 무엇을 할지 명시적으로 말해주지 않으면 그냥 가만히 앉아 있을 것입니다. GPT-5.3-Codex는 제가 요청하지 않은 범위까지 넘보지 않으면서도, 누가 봐도 유용한 일을 알아서 처리합니다.

### 놀라운 교차 레포지토리(Cross-Repo) 작업 능력
저는 보통 모델에게 할당된 단일 레포지토리 이상의 접근 권한을 부여합니다. 이는 완전히 새로운 워크플로우를 열어주었습니다. "이 장비에서 X를 위한 API를 노출하는 레포지토리를 찾아줘"라고 말하면, 모델은 직접 찾아가서 패턴을 학습하고 현재 레포지토리에 올바르게 적용한 뒤 계속 진행합니다. 심지어 다른 레포지토리에서 변경을 수행하고 푸시한 뒤, 길을 잃지 않고 원래의 메인 스레드로 돌아올 수도 있습니다. 모델이 이렇게 제 컴퓨터 이곳저곳을 옮겨 다니는 것을 보는 것은 여전히 좀 비현실적입니다.

### 배포까지 모든 과정을 완결 짓습니다 (Railway CLI)
저는 모델에게 Railway CLI 접근 권한을 주었고, 모델은 저를 대신해 개발의 전체 수명 주기 루프를 닫을 수 있었습니다. "준비되면 이걸 Railway에 올리고, 완벽하게 작동하는지 확인해줘"라고 말하면 그냥 알아서 합니다. 코드를 변경하고, 푸시하고, 배포한 뒤, 실제 운영 URL을 확인하고 로그를 추적하며 실제로 작동할 때까지 반복 작업을 계속합니다.

다른 모델에서도 이런 편린을 본 적이 있습니다. Opus는 로그를 활용해 스스로 수정하는 일을 꽤 잘 해냅니다. Antigravity의 Gemini 3 Pro는 브라우저 기반의 반복 작업을 포함하고 있고, 대부분의 코딩 도구에는 이제 이 루프의 일부를 위한 플러그인이 있습니다. 하지만 여기서의 차이점은 마침내 **진정한 폐쇄 루프(closed loop)**처럼 느껴진다는 것입니다. 거의 매번 성공합니다. 정말 말도 안 되는 광경입니다. 빈 프로젝트를 시작하고 컴퓨터를 떠났다가 한두 시간(또는 그 이상) 뒤에 돌아오면, GitHub에는 여러 개의 새로운 코드베이스가 있고, Railway에는 새로운 배포가 완료되어 있으며, 전체 시스템이 완벽하게 상호작용하고 있는 것을 볼 수 있습니다.

### 언제 무엇을 사용할 것인가 (나의 실제 결정 규칙)
현재 제 방식은 다음과 같이 정착되었습니다.

Opus 4.5는 여전히 빠른 작업과 빠른 반복 루프를 위한 기본 모델입니다. 특히 깊이보다는 속도가 더 중요할 때 그렇습니다. 하지만 매일 사용 빈도가 줄어들고 있습니다. 최근에는 평소 같으면 Opus를 썼을 법한 자잘한 이슈들을 묶어서 Codex를 위한 하나의 거대한 프롬프트로 만들고, 한 시간 정도 실행시켜 둡니다.

**GPT-5.3-Codex**는 작업 기간이 길고, 까다롭고, 제약 조건이 많거나, 정말 틀리고 싶지 않은 작업을 할 때 선택합니다. 작업을 시작해두고 자리를 비우고 싶을 때 사용하는 모델입니다. 하지만 다시 말하지만, 쓰면 쓸수록 더 많은 일에 쓰고 싶어지기 때문에 앞으로 몇 주 안에 Codex가 제 업무의 훨씬 더 많은 부분을 차지하게 될 것으로 예상합니다.

UI와 스타일링은 여전히 GPT-5.3-Codex의 강점이 아닙니다. 이 분야는 Opus가 더 낫고, 스타일링에 관해서는 Gemini 3 Pro가 제가 사용해 본 중 최고입니다.

GPT-5.2 리뷰에서 저는 모델이 놀랍지만 너무 느리다고 말했습니다. GPT-5.3-Codex가 획기적으로 더 빨라진 것은 아닙니다. 하지만 묘하게도 저에게 속도는 더 이상 큰 문제가 되지 않습니다. 장기 작업에서 워낙 신뢰도가 높아서 그냥 실행시켜 두고 나중에 돌아오면 되기 때문입니다. 속도는 여전히 일종의 '세금'과 같지만, 모델이 이 정도로 잘 작동한다면 더 이상 걸림돌이 되지 않습니다.

추론 모드(reasoning modes)에 관해서는, OpenAI는 Medium을 권장하며 이 역시 강력하지만, 자리를 비울 계획이라면 Extra High가 확실히 합리적입니다. 저에게 Extra High는 "시간이 걸려도 좋으니 제대로 해라"라는 상황에 딱 맞는 설정입니다.

### 더 좋아졌지만, 예전만큼 재미있지는 않습니다
소소한 불편함(paper cuts)들이 있는데, 가장 이상한 점은 모델이 몇 시간 동안 돌아가고 있을 때 정작 제가 무엇을 해야 할지 모를 때가 있다는 것입니다. Claude를 쓸 때는 메인 작업이 한 번에 모든 것을 해내지 못할 것이기 때문에 다른 작은 일들을 위해 병렬로 작업을 실행하곤 했습니다. 하지만 GPT-5.3-Codex는 능력이 워낙 출중해서 한 번의 실행으로 제가 원하는 대부분의, 혹은 모든 것을 처리해 버립니다. 놀라운 일이지만, 때로는 제가 손을 놓고 멍하니 앉아 있게 만듭니다. 참 묘한 적응 과정이고, 여전히 익숙해지는 중입니다.

### 기타 참고 사항 (Side Notes)

**프롬프트 및 에이전트 설계**
저는 에이전트를 많이 만듭니다. GPT-5.3-Codex는 프롬프트 아키텍처 자체를 설계하기에 가장 좋은 모델은 아닙니다. 프롬프트에 무엇이 들어가야 하는지, 에이전트 흐름을 어떻게 짜야 하는지에 대해 때때로 깊이 고민하지 않은 결정을 내리며, 제가 아끼는 에이전트 흐름을 망가뜨린 적도 있습니다. 프롬프트를 다듬고 에이전트를 구축할 때는 여전히 Opus를 사용합니다.
다만 한 가지 예외가 있다면, 에이전트가 수행해야 할 작업에 대해 매우 명시적인 검증 수단과 구체적인 출력 및 동작 테스트를 제공할 경우입니다. 이럴 때는 첫 시도가 실패하더라도 성공할 때까지 계속 파고듭니다. 방향만 명확하다면, GPT-5.3-Codex는 에이전트 주변의 시스템을 구축하고 작업을 실행하는 데 탁월합니다.

**상태 설명(Status Narration)의 불안정함**
상태 설명이란 모델이 작업하면서 "이 문제를 확인했고, X를 체크한 뒤 Y를 실행하겠습니다"라고 말하는 것을 의미합니다. 보통은 꽤 잘 합니다. 하지만 가끔 한동안 설명을 멈출 때가 있는데, 이로 인해 작업 중간에 무슨 일이 일어나고 있는지 파악하기가 생각보다 어렵습니다. UI의 작업 체크박스가 큰 도움이 됩니다. 계획된 작업 목록이 표시되고 체크되는 것을 볼 수 있습니다. 하지만 이 체크박스들이 작업이 끝날 때까지 업데이트되지 않는 현상을 발견했습니다. 이는 주로 가시성 문제이며, 제 경험상 결과물의 품질에 큰 영향을 미치지는 않았습니다.

**실행 요약이 너무 기술적임**
또 다른 불편함은 작업이 끝난 후 모델이 매우 전문적인 용어(jargon)를 남발하며 업데이트를 준다는 점입니다. 기초 지식이 부족한 빌더라면 꽤 힘들 것입니다. 종종 쉬운 영어로 다시 설명해달라고 요청해야 할 것입니다. 기술적인 지식이 있더라도 짜증 날 정도로 밀도가 높을 때가 있습니다. 대부분의 경우 저는 무엇이 바뀌었고 잘 작동했는지를 빠르고 명확하게 알고 싶을 뿐이지, 기술적인 용어의 늪에 빠지고 싶지 않습니다. 이런 모델들을 사용하는 목적 자체가 그런 복잡함을 피하기 위함인데 말이죠.

**Mac 앱 리뷰를 제외한 이유**
몇몇 분들이 초기 접근 권한이 있었음에도 왜 Codex Mac 앱을 리뷰하지 않았는지 물어보셨습니다. 이유는 간단합니다. 5.3-Codex 모델 자체에 너무 압도되어 다른 것에 시간을 쓸 여력이 없었기 때문입니다. 하지만 앱 자체도 훌륭합니다. 한 곳에서 많은 실행을 관리하는 것은 정말 유용하며, 로컬/클라우드 실행 지원 및 작업 트리(worktrees)/브랜치 지원도 훌륭합니다. 여전히 몇 가지 UI 버그(특히 실행 중 업데이트 관련)가 보이고 인터페이스를 다듬을 여지가 있지만, 모델의 품질이 워낙 압도적이어서 제 관심을 독차지했습니다.

### 이 모델이 나의 업무 방식을 바꾸었습니다
이제 제 워크플로우는 이렇습니다. 극도로 상세한 프롬프트를 작성하고, 명확한 검증 및 테스트 케이스를 미리 정의한 다음, 모델을 실행시킵니다.

GPT-5.3-Codex는 완전한 자율성이 운영 측면에서 실제로 체감되기 시작하는 최초의 코딩 모델입니다. 완벽하지는 않습니다. 속도는 여전히 큰 단점입니다. 하지만 모호함 속에서의 판단력이 더 뛰어나고, 장기적인 안정성이 더 좋으며, 검증 목표를 주었을 때 놀라울 정도로 신뢰할 수 있기 때문에 이제 제가 하는 대부분의 작업에서 가장 선호하는 모델이 되었습니다.

빠른 작업에는 여전히 Opus 4.5가 제격입니다. 하지만 어렵거나, 길거나, 정말 틀리고 싶지 않은 작업이라면, 이 모델은 제가 안심하고 실행 버튼을 누른 채 컴퓨터를 떠나서... 실제로 결과물이 완성되어 있기를 기대할 수 있는 최초의 모델입니다.
